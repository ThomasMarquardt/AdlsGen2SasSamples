{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMHzw+Yc3LtDOopg6Hr23mG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThomasMarquardt/AdlsGen2SasSamples/blob/master/FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_jCHr50Movo",
        "outputId": "41f312c4-808a-431d-b437-091644c33ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/NLP\n",
            "Enter GitHub PAT··········\n",
            "fatal: destination path 'ut-nlp-fp' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "from getpass import getpass\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/NLP\n",
        "os.environ['USER'] = 'ThomasMarquardt'\n",
        "os.environ['PASS'] = getpass(\"Enter GitHub PAT\")\n",
        "os.environ['REPO'] = 'ut-nlp-fp'\n",
        "!git clone https://$USER:$PASS@github.com/$USER/$REPO.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/NLP/ut-nlp-fp\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfE67c_pN8VG",
        "outputId": "cca4eb2f-6ab7-4cfc-9ab6-e4165240d7fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NLP/ut-nlp-fp\n",
            "Collecting accelerate (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.66.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.35.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.19.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets->-r requirements.txt (line 2))\n",
            "  Downloading pyarrow_hotfix-0.5-py3-none-any.whl (7.8 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.4.1)\n",
            "Collecting multiprocess (from datasets->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.8.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, accelerate, datasets\n",
            "Successfully installed accelerate-0.24.1 datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 run.py --do_train --task nli --dataset snli --output_dir ./trained_model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ukmx2T5VR4Kx",
        "outputId": "b04f37ac-e27b-4e51-cf80-022f51920a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-19 20:46:42.644024: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-19 20:46:42.644125: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-19 20:46:42.644180: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-19 20:46:44.051701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 3.82k/3.82k [00:00<00:00, 14.9MB/s]\n",
            "Downloading metadata: 100% 1.90k/1.90k [00:00<00:00, 10.3MB/s]\n",
            "Downloading readme: 100% 14.1k/14.1k [00:00<00:00, 25.3MB/s]\n",
            "Downloading: 100% 1.93k/1.93k [00:00<00:00, 8.73MB/s]\n",
            "Downloading: 100% 1.26M/1.26M [00:00<00:00, 9.50MB/s]\n",
            "Downloading: 100% 65.9M/65.9M [00:01<00:00, 62.9MB/s]\n",
            "Downloading: 100% 1.26M/1.26M [00:00<00:00, 8.70MB/s]\n",
            "config.json: 100% 665/665 [00:00<00:00, 1.99MB/s]\n",
            "pytorch_model.bin: 100% 54.2M/54.2M [00:00<00:00, 193MB/s]\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "tokenizer_config.json: 100% 29.0/29.0 [00:00<00:00, 164kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 5.21MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 26.4MB/s]\n",
            "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
            "Filter: 100% 10000/10000 [00:00<00:00, 105781.07 examples/s]\n",
            "Filter: 100% 550152/550152 [00:04<00:00, 122878.01 examples/s]\n",
            "Filter: 100% 10000/10000 [00:00<00:00, 110891.78 examples/s]\n",
            "Map (num_proc=2): 100% 549367/549367 [01:59<00:00, 4588.37 examples/s]\n",
            "  0% 0/206013 [00:00<?, ?it/s]You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.9209, 'learning_rate': 4.987864843480751e-05, 'epoch': 0.01}\n",
            "{'loss': 0.7265, 'learning_rate': 4.975729686961503e-05, 'epoch': 0.01}\n",
            "{'loss': 0.6746, 'learning_rate': 4.963594530442254e-05, 'epoch': 0.02}\n",
            "{'loss': 0.634, 'learning_rate': 4.951459373923005e-05, 'epoch': 0.03}\n",
            "{'loss': 0.6268, 'learning_rate': 4.9393242174037564e-05, 'epoch': 0.04}\n",
            "{'loss': 0.6105, 'learning_rate': 4.927189060884507e-05, 'epoch': 0.04}\n",
            "{'loss': 0.6024, 'learning_rate': 4.9150539043652585e-05, 'epoch': 0.05}\n",
            "{'loss': 0.5962, 'learning_rate': 4.90291874784601e-05, 'epoch': 0.06}\n",
            "{'loss': 0.6187, 'learning_rate': 4.890783591326761e-05, 'epoch': 0.07}\n",
            "{'loss': 0.5733, 'learning_rate': 4.8786484348075126e-05, 'epoch': 0.07}\n",
            "{'loss': 0.5769, 'learning_rate': 4.866513278288264e-05, 'epoch': 0.08}\n",
            "{'loss': 0.556, 'learning_rate': 4.8543781217690146e-05, 'epoch': 0.09}\n",
            "{'loss': 0.5668, 'learning_rate': 4.842242965249766e-05, 'epoch': 0.09}\n",
            "{'loss': 0.561, 'learning_rate': 4.8301078087305174e-05, 'epoch': 0.1}\n",
            "{'loss': 0.54, 'learning_rate': 4.817972652211268e-05, 'epoch': 0.11}\n",
            "{'loss': 0.5436, 'learning_rate': 4.80583749569202e-05, 'epoch': 0.12}\n",
            "{'loss': 0.5477, 'learning_rate': 4.793702339172771e-05, 'epoch': 0.12}\n",
            "{'loss': 0.535, 'learning_rate': 4.781567182653522e-05, 'epoch': 0.13}\n",
            "{'loss': 0.5536, 'learning_rate': 4.7694320261342736e-05, 'epoch': 0.14}\n",
            "{'loss': 0.5497, 'learning_rate': 4.757296869615024e-05, 'epoch': 0.15}\n",
            "{'loss': 0.5211, 'learning_rate': 4.7451617130957756e-05, 'epoch': 0.15}\n",
            "{'loss': 0.5518, 'learning_rate': 4.733026556576527e-05, 'epoch': 0.16}\n",
            "{'loss': 0.5441, 'learning_rate': 4.720891400057278e-05, 'epoch': 0.17}\n",
            "{'loss': 0.5292, 'learning_rate': 4.70875624353803e-05, 'epoch': 0.17}\n",
            "{'loss': 0.524, 'learning_rate': 4.6966210870187804e-05, 'epoch': 0.18}\n",
            "{'loss': 0.5382, 'learning_rate': 4.684485930499532e-05, 'epoch': 0.19}\n",
            "{'loss': 0.5218, 'learning_rate': 4.672350773980283e-05, 'epoch': 0.2}\n",
            "{'loss': 0.4966, 'learning_rate': 4.660215617461034e-05, 'epoch': 0.2}\n",
            "{'loss': 0.5271, 'learning_rate': 4.648080460941785e-05, 'epoch': 0.21}\n",
            "{'loss': 0.5184, 'learning_rate': 4.6359453044225366e-05, 'epoch': 0.22}\n",
            "{'loss': 0.5061, 'learning_rate': 4.623810147903288e-05, 'epoch': 0.23}\n",
            "{'loss': 0.5179, 'learning_rate': 4.611674991384039e-05, 'epoch': 0.23}\n",
            "{'loss': 0.5087, 'learning_rate': 4.599539834864791e-05, 'epoch': 0.24}\n",
            "{'loss': 0.5234, 'learning_rate': 4.5874046783455414e-05, 'epoch': 0.25}\n",
            "{'loss': 0.5297, 'learning_rate': 4.575269521826293e-05, 'epoch': 0.25}\n",
            "{'loss': 0.5282, 'learning_rate': 4.563134365307044e-05, 'epoch': 0.26}\n",
            "{'loss': 0.4869, 'learning_rate': 4.550999208787795e-05, 'epoch': 0.27}\n",
            "{'loss': 0.5003, 'learning_rate': 4.538864052268547e-05, 'epoch': 0.28}\n",
            "{'loss': 0.5025, 'learning_rate': 4.5267288957492976e-05, 'epoch': 0.28}\n",
            "{'loss': 0.5052, 'learning_rate': 4.514593739230048e-05, 'epoch': 0.29}\n",
            "{'loss': 0.4851, 'learning_rate': 4.5024585827108e-05, 'epoch': 0.3}\n",
            "{'loss': 0.4967, 'learning_rate': 4.490323426191551e-05, 'epoch': 0.31}\n",
            "{'loss': 0.4917, 'learning_rate': 4.4781882696723024e-05, 'epoch': 0.31}\n",
            "{'loss': 0.4946, 'learning_rate': 4.466053113153054e-05, 'epoch': 0.32}\n",
            "{'loss': 0.4988, 'learning_rate': 4.4539179566338044e-05, 'epoch': 0.33}\n",
            "{'loss': 0.48, 'learning_rate': 4.4417828001145565e-05, 'epoch': 0.33}\n",
            "{'loss': 0.5132, 'learning_rate': 4.429647643595307e-05, 'epoch': 0.34}\n",
            "{'loss': 0.4855, 'learning_rate': 4.4175124870760585e-05, 'epoch': 0.35}\n",
            "{'loss': 0.472, 'learning_rate': 4.40537733055681e-05, 'epoch': 0.36}\n",
            "{'loss': 0.5205, 'learning_rate': 4.393242174037561e-05, 'epoch': 0.36}\n",
            "{'loss': 0.4873, 'learning_rate': 4.381107017518312e-05, 'epoch': 0.37}\n",
            "{'loss': 0.4949, 'learning_rate': 4.368971860999063e-05, 'epoch': 0.38}\n",
            "{'loss': 0.5116, 'learning_rate': 4.356836704479815e-05, 'epoch': 0.39}\n",
            "{'loss': 0.4767, 'learning_rate': 4.3447015479605654e-05, 'epoch': 0.39}\n",
            "{'loss': 0.4917, 'learning_rate': 4.3325663914413174e-05, 'epoch': 0.4}\n",
            "{'loss': 0.4801, 'learning_rate': 4.320431234922068e-05, 'epoch': 0.41}\n",
            "{'loss': 0.4582, 'learning_rate': 4.3082960784028195e-05, 'epoch': 0.42}\n",
            "{'loss': 0.4876, 'learning_rate': 4.296160921883571e-05, 'epoch': 0.42}\n",
            "{'loss': 0.4969, 'learning_rate': 4.2840257653643216e-05, 'epoch': 0.43}\n",
            "{'loss': 0.4877, 'learning_rate': 4.2718906088450736e-05, 'epoch': 0.44}\n",
            "{'loss': 0.4793, 'learning_rate': 4.259755452325824e-05, 'epoch': 0.44}\n",
            "{'loss': 0.4664, 'learning_rate': 4.247620295806575e-05, 'epoch': 0.45}\n",
            "{'loss': 0.4711, 'learning_rate': 4.235485139287327e-05, 'epoch': 0.46}\n",
            "{'loss': 0.4695, 'learning_rate': 4.223349982768078e-05, 'epoch': 0.47}\n",
            "{'loss': 0.4815, 'learning_rate': 4.211214826248829e-05, 'epoch': 0.47}\n",
            "{'loss': 0.4733, 'learning_rate': 4.1990796697295805e-05, 'epoch': 0.48}\n",
            "{'loss': 0.4645, 'learning_rate': 4.186944513210331e-05, 'epoch': 0.49}\n",
            "{'loss': 0.4964, 'learning_rate': 4.1748093566910825e-05, 'epoch': 0.5}\n",
            "{'loss': 0.4756, 'learning_rate': 4.162674200171834e-05, 'epoch': 0.5}\n",
            "{'loss': 0.4552, 'learning_rate': 4.150539043652585e-05, 'epoch': 0.51}\n",
            "{'loss': 0.46, 'learning_rate': 4.1384038871333367e-05, 'epoch': 0.52}\n",
            "{'loss': 0.4888, 'learning_rate': 4.126268730614088e-05, 'epoch': 0.52}\n",
            "{'loss': 0.455, 'learning_rate': 4.114133574094839e-05, 'epoch': 0.53}\n",
            "{'loss': 0.4656, 'learning_rate': 4.10199841757559e-05, 'epoch': 0.54}\n",
            "{'loss': 0.4853, 'learning_rate': 4.0898632610563415e-05, 'epoch': 0.55}\n",
            "{'loss': 0.4619, 'learning_rate': 4.077728104537092e-05, 'epoch': 0.55}\n",
            "{'loss': 0.4649, 'learning_rate': 4.065592948017844e-05, 'epoch': 0.56}\n",
            "{'loss': 0.4725, 'learning_rate': 4.053457791498595e-05, 'epoch': 0.57}\n",
            "{'loss': 0.4629, 'learning_rate': 4.041322634979346e-05, 'epoch': 0.58}\n",
            "{'loss': 0.479, 'learning_rate': 4.0291874784600976e-05, 'epoch': 0.58}\n",
            "{'loss': 0.4506, 'learning_rate': 4.017052321940848e-05, 'epoch': 0.59}\n",
            "{'loss': 0.4563, 'learning_rate': 4.0049171654216e-05, 'epoch': 0.6}\n",
            "{'loss': 0.4352, 'learning_rate': 3.992782008902351e-05, 'epoch': 0.6}\n",
            "{'loss': 0.4599, 'learning_rate': 3.980646852383102e-05, 'epoch': 0.61}\n",
            "{'loss': 0.454, 'learning_rate': 3.968511695863854e-05, 'epoch': 0.62}\n",
            "{'loss': 0.4414, 'learning_rate': 3.9563765393446045e-05, 'epoch': 0.63}\n",
            "{'loss': 0.4699, 'learning_rate': 3.944241382825356e-05, 'epoch': 0.63}\n",
            "{'loss': 0.4392, 'learning_rate': 3.932106226306107e-05, 'epoch': 0.64}\n",
            "{'loss': 0.456, 'learning_rate': 3.9199710697868586e-05, 'epoch': 0.65}\n",
            "{'loss': 0.448, 'learning_rate': 3.907835913267609e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4544, 'learning_rate': 3.8957007567483607e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4541, 'learning_rate': 3.883565600229112e-05, 'epoch': 0.67}\n",
            "{'loss': 0.4517, 'learning_rate': 3.8714304437098634e-05, 'epoch': 0.68}\n",
            "{'loss': 0.4511, 'learning_rate': 3.859295287190615e-05, 'epoch': 0.68}\n",
            "{'loss': 0.4537, 'learning_rate': 3.8471601306713655e-05, 'epoch': 0.69}\n",
            "{'loss': 0.4621, 'learning_rate': 3.835024974152117e-05, 'epoch': 0.7}\n",
            "{'loss': 0.4458, 'learning_rate': 3.822889817632868e-05, 'epoch': 0.71}\n",
            "{'loss': 0.4448, 'learning_rate': 3.810754661113619e-05, 'epoch': 0.71}\n",
            "{'loss': 0.433, 'learning_rate': 3.798619504594371e-05, 'epoch': 0.72}\n",
            "{'loss': 0.4597, 'learning_rate': 3.7864843480751216e-05, 'epoch': 0.73}\n",
            "{'loss': 0.4621, 'learning_rate': 3.774349191555872e-05, 'epoch': 0.74}\n",
            "{'loss': 0.4449, 'learning_rate': 3.7622140350366244e-05, 'epoch': 0.74}\n",
            "{'loss': 0.4548, 'learning_rate': 3.750078878517375e-05, 'epoch': 0.75}\n",
            "{'loss': 0.4411, 'learning_rate': 3.7379437219981264e-05, 'epoch': 0.76}\n",
            "{'loss': 0.4444, 'learning_rate': 3.725808565478878e-05, 'epoch': 0.76}\n",
            "{'loss': 0.4662, 'learning_rate': 3.7136734089596285e-05, 'epoch': 0.77}\n",
            "{'loss': 0.4725, 'learning_rate': 3.7015382524403805e-05, 'epoch': 0.78}\n",
            "{'loss': 0.4468, 'learning_rate': 3.689403095921131e-05, 'epoch': 0.79}\n",
            "{'loss': 0.4406, 'learning_rate': 3.6772679394018826e-05, 'epoch': 0.79}\n",
            "{'loss': 0.4762, 'learning_rate': 3.665132782882634e-05, 'epoch': 0.8}\n",
            "{'loss': 0.447, 'learning_rate': 3.6529976263633853e-05, 'epoch': 0.81}\n",
            "{'loss': 0.4519, 'learning_rate': 3.640862469844136e-05, 'epoch': 0.82}\n",
            "{'loss': 0.4403, 'learning_rate': 3.6287273133248874e-05, 'epoch': 0.82}\n",
            "{'loss': 0.4305, 'learning_rate': 3.616592156805639e-05, 'epoch': 0.83}\n",
            "{'loss': 0.4401, 'learning_rate': 3.6044570002863895e-05, 'epoch': 0.84}\n",
            "{'loss': 0.4383, 'learning_rate': 3.5923218437671415e-05, 'epoch': 0.84}\n",
            "{'loss': 0.4437, 'learning_rate': 3.580186687247892e-05, 'epoch': 0.85}\n",
            "{'loss': 0.4329, 'learning_rate': 3.5680515307286436e-05, 'epoch': 0.86}\n",
            "{'loss': 0.4327, 'learning_rate': 3.555916374209395e-05, 'epoch': 0.87}\n",
            "{'loss': 0.4668, 'learning_rate': 3.5437812176901456e-05, 'epoch': 0.87}\n",
            "{'loss': 0.4566, 'learning_rate': 3.531646061170898e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4301, 'learning_rate': 3.5195109046516484e-05, 'epoch': 0.89}\n",
            "{'loss': 0.4389, 'learning_rate': 3.507375748132399e-05, 'epoch': 0.9}\n",
            "{'loss': 0.4355, 'learning_rate': 3.495240591613151e-05, 'epoch': 0.9}\n",
            "{'loss': 0.4299, 'learning_rate': 3.483105435093902e-05, 'epoch': 0.91}\n",
            "{'loss': 0.4126, 'learning_rate': 3.470970278574653e-05, 'epoch': 0.92}\n",
            "{'loss': 0.4593, 'learning_rate': 3.4588351220554045e-05, 'epoch': 0.92}\n",
            "{'loss': 0.4123, 'learning_rate': 3.446699965536155e-05, 'epoch': 0.93}\n",
            "{'loss': 0.4252, 'learning_rate': 3.4345648090169066e-05, 'epoch': 0.94}\n",
            "{'loss': 0.4315, 'learning_rate': 3.422429652497658e-05, 'epoch': 0.95}\n",
            "{'loss': 0.4242, 'learning_rate': 3.4102944959784094e-05, 'epoch': 0.95}\n",
            "{'loss': 0.4303, 'learning_rate': 3.398159339459161e-05, 'epoch': 0.96}\n",
            "{'loss': 0.4531, 'learning_rate': 3.386024182939912e-05, 'epoch': 0.97}\n",
            "{'loss': 0.4274, 'learning_rate': 3.373889026420663e-05, 'epoch': 0.98}\n",
            "{'loss': 0.4532, 'learning_rate': 3.361753869901414e-05, 'epoch': 0.98}\n",
            "{'loss': 0.4538, 'learning_rate': 3.3496187133821655e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4163, 'learning_rate': 3.337483556862916e-05, 'epoch': 1.0}\n",
            "{'loss': 0.414, 'learning_rate': 3.325348400343668e-05, 'epoch': 1.0}\n",
            "{'loss': 0.4065, 'learning_rate': 3.313213243824419e-05, 'epoch': 1.01}\n",
            "{'loss': 0.4065, 'learning_rate': 3.30107808730517e-05, 'epoch': 1.02}\n",
            "{'loss': 0.4059, 'learning_rate': 3.288942930785922e-05, 'epoch': 1.03}\n",
            "{'loss': 0.3927, 'learning_rate': 3.2768077742666724e-05, 'epoch': 1.03}\n",
            "{'loss': 0.3999, 'learning_rate': 3.264672617747424e-05, 'epoch': 1.04}\n",
            "{'loss': 0.392, 'learning_rate': 3.252537461228175e-05, 'epoch': 1.05}\n",
            "{'loss': 0.4213, 'learning_rate': 3.240402304708926e-05, 'epoch': 1.06}\n",
            "{'loss': 0.4211, 'learning_rate': 3.228267148189678e-05, 'epoch': 1.06}\n",
            "{'loss': 0.4208, 'learning_rate': 3.2161319916704286e-05, 'epoch': 1.07}\n",
            "{'loss': 0.4083, 'learning_rate': 3.20399683515118e-05, 'epoch': 1.08}\n",
            "{'loss': 0.4043, 'learning_rate': 3.191861678631931e-05, 'epoch': 1.08}\n",
            "{'loss': 0.4157, 'learning_rate': 3.179726522112683e-05, 'epoch': 1.09}\n",
            "{'loss': 0.4146, 'learning_rate': 3.1675913655934334e-05, 'epoch': 1.1}\n",
            "{'loss': 0.4034, 'learning_rate': 3.155456209074185e-05, 'epoch': 1.11}\n",
            "{'loss': 0.4154, 'learning_rate': 3.143321052554936e-05, 'epoch': 1.11}\n",
            "{'loss': 0.4148, 'learning_rate': 3.131185896035687e-05, 'epoch': 1.12}\n",
            "{'loss': 0.405, 'learning_rate': 3.119050739516439e-05, 'epoch': 1.13}\n",
            "{'loss': 0.4244, 'learning_rate': 3.1069155829971895e-05, 'epoch': 1.14}\n",
            "{'loss': 0.406, 'learning_rate': 3.094780426477941e-05, 'epoch': 1.14}\n",
            "{'loss': 0.4101, 'learning_rate': 3.082645269958692e-05, 'epoch': 1.15}\n",
            "{'loss': 0.4086, 'learning_rate': 3.070510113439443e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4171, 'learning_rate': 3.058374956920195e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4173, 'learning_rate': 3.0462398004009457e-05, 'epoch': 1.17}\n",
            "{'loss': 0.3946, 'learning_rate': 3.0341046438816967e-05, 'epoch': 1.18}\n",
            "{'loss': 0.4063, 'learning_rate': 3.021969487362448e-05, 'epoch': 1.19}\n",
            "{'loss': 0.408, 'learning_rate': 3.009834330843199e-05, 'epoch': 1.19}\n",
            "{'loss': 0.4244, 'learning_rate': 2.997699174323951e-05, 'epoch': 1.2}\n",
            "{'loss': 0.4036, 'learning_rate': 2.985564017804702e-05, 'epoch': 1.21}\n",
            "{'loss': 0.3984, 'learning_rate': 2.9734288612854526e-05, 'epoch': 1.22}\n",
            "{'loss': 0.4192, 'learning_rate': 2.9612937047662043e-05, 'epoch': 1.22}\n",
            "{'loss': 0.4005, 'learning_rate': 2.9491585482469553e-05, 'epoch': 1.23}\n",
            "{'loss': 0.3993, 'learning_rate': 2.9370233917277067e-05, 'epoch': 1.24}\n",
            "{'loss': 0.4119, 'learning_rate': 2.9248882352084577e-05, 'epoch': 1.25}\n",
            "{'loss': 0.406, 'learning_rate': 2.9127530786892094e-05, 'epoch': 1.25}\n",
            "{'loss': 0.4362, 'learning_rate': 2.9006179221699604e-05, 'epoch': 1.26}\n",
            "{'loss': 0.3986, 'learning_rate': 2.888482765650711e-05, 'epoch': 1.27}\n",
            "{'loss': 0.3932, 'learning_rate': 2.876347609131463e-05, 'epoch': 1.27}\n",
            "{'loss': 0.3985, 'learning_rate': 2.864212452612214e-05, 'epoch': 1.28}\n",
            "{'loss': 0.4142, 'learning_rate': 2.8520772960929652e-05, 'epoch': 1.29}\n",
            "{'loss': 0.4037, 'learning_rate': 2.8399421395737163e-05, 'epoch': 1.3}\n",
            "{'loss': 0.3962, 'learning_rate': 2.8278069830544673e-05, 'epoch': 1.3}\n",
            "{'loss': 0.4009, 'learning_rate': 2.815671826535219e-05, 'epoch': 1.31}\n",
            "{'loss': 0.4162, 'learning_rate': 2.8035366700159697e-05, 'epoch': 1.32}\n",
            "{'loss': 0.4176, 'learning_rate': 2.7914015134967214e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4257, 'learning_rate': 2.7792663569774724e-05, 'epoch': 1.33}\n",
            "{'loss': 0.3992, 'learning_rate': 2.7671312004582235e-05, 'epoch': 1.34}\n",
            "{'loss': 0.4011, 'learning_rate': 2.754996043938975e-05, 'epoch': 1.35}\n",
            "{'loss': 0.4006, 'learning_rate': 2.742860887419726e-05, 'epoch': 1.35}\n",
            "{'loss': 0.4062, 'learning_rate': 2.7307257309004776e-05, 'epoch': 1.36}\n",
            "{'loss': 0.403, 'learning_rate': 2.7185905743812283e-05, 'epoch': 1.37}\n",
            "{'loss': 0.3997, 'learning_rate': 2.70645541786198e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3968, 'learning_rate': 2.694320261342731e-05, 'epoch': 1.38}\n",
            "{'loss': 0.391, 'learning_rate': 2.682185104823482e-05, 'epoch': 1.39}\n",
            "{'loss': 0.4157, 'learning_rate': 2.6700499483042334e-05, 'epoch': 1.4}\n",
            "{'loss': 0.3886, 'learning_rate': 2.6579147917849845e-05, 'epoch': 1.41}\n",
            "{'loss': 0.4011, 'learning_rate': 2.645779635265736e-05, 'epoch': 1.41}\n",
            "{'loss': 0.4014, 'learning_rate': 2.633644478746487e-05, 'epoch': 1.42}\n",
            "{'loss': 0.3784, 'learning_rate': 2.621509322227238e-05, 'epoch': 1.43}\n",
            "{'loss': 0.4005, 'learning_rate': 2.6093741657079896e-05, 'epoch': 1.43}\n",
            "{'loss': 0.3922, 'learning_rate': 2.5972390091887406e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4158, 'learning_rate': 2.585103852669492e-05, 'epoch': 1.45}\n",
            "{'loss': 0.3804, 'learning_rate': 2.572968696150243e-05, 'epoch': 1.46}\n",
            "{'loss': 0.399, 'learning_rate': 2.560833539630994e-05, 'epoch': 1.46}\n",
            "{'loss': 0.4322, 'learning_rate': 2.5486983831117454e-05, 'epoch': 1.47}\n",
            "{'loss': 0.3884, 'learning_rate': 2.5365632265924965e-05, 'epoch': 1.48}\n",
            "{'loss': 0.3995, 'learning_rate': 2.524428070073248e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4187, 'learning_rate': 2.5122929135539992e-05, 'epoch': 1.49}\n",
            "{'loss': 0.3985, 'learning_rate': 2.5001577570347502e-05, 'epoch': 1.5}\n",
            "{'loss': 0.3985, 'learning_rate': 2.4880226005155016e-05, 'epoch': 1.51}\n",
            "{'loss': 0.3878, 'learning_rate': 2.475887443996253e-05, 'epoch': 1.51}\n",
            "{'loss': 0.4266, 'learning_rate': 2.463752287477004e-05, 'epoch': 1.52}\n",
            "{'loss': 0.4061, 'learning_rate': 2.451617130957755e-05, 'epoch': 1.53}\n",
            "{'loss': 0.3824, 'learning_rate': 2.4394819744385064e-05, 'epoch': 1.54}\n",
            "{'loss': 0.3916, 'learning_rate': 2.4273468179192578e-05, 'epoch': 1.54}\n",
            "{'loss': 0.3944, 'learning_rate': 2.4152116614000088e-05, 'epoch': 1.55}\n",
            "{'loss': 0.399, 'learning_rate': 2.40307650488076e-05, 'epoch': 1.56}\n",
            "{'loss': 0.3952, 'learning_rate': 2.3909413483615112e-05, 'epoch': 1.57}\n",
            "{'loss': 0.3757, 'learning_rate': 2.3788061918422626e-05, 'epoch': 1.57}\n",
            "{'loss': 0.4057, 'learning_rate': 2.3666710353230136e-05, 'epoch': 1.58}\n",
            "{'loss': 0.4116, 'learning_rate': 2.354535878803765e-05, 'epoch': 1.59}\n",
            "{'loss': 0.39, 'learning_rate': 2.3424007222845163e-05, 'epoch': 1.59}\n",
            "{'loss': 0.3748, 'learning_rate': 2.3302655657652674e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3915, 'learning_rate': 2.3181304092460184e-05, 'epoch': 1.61}\n",
            "{'loss': 0.3969, 'learning_rate': 2.3059952527267698e-05, 'epoch': 1.62}\n",
            "{'loss': 0.3942, 'learning_rate': 2.293860096207521e-05, 'epoch': 1.62}\n",
            "{'loss': 0.3789, 'learning_rate': 2.2817249396882722e-05, 'epoch': 1.63}\n",
            "{'loss': 0.4023, 'learning_rate': 2.2695897831690235e-05, 'epoch': 1.64}\n",
            "{'loss': 0.3988, 'learning_rate': 2.2574546266497746e-05, 'epoch': 1.65}\n",
            "{'loss': 0.3832, 'learning_rate': 2.245319470130526e-05, 'epoch': 1.65}\n",
            "{'loss': 0.3881, 'learning_rate': 2.233184313611277e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3916, 'learning_rate': 2.2210491570920283e-05, 'epoch': 1.67}\n",
            "{'loss': 0.3868, 'learning_rate': 2.2089140005727797e-05, 'epoch': 1.67}\n",
            "{'loss': 0.3811, 'learning_rate': 2.1967788440535304e-05, 'epoch': 1.68}\n",
            "{'loss': 0.3802, 'learning_rate': 2.1846436875342818e-05, 'epoch': 1.69}\n",
            "{'loss': 0.3923, 'learning_rate': 2.172508531015033e-05, 'epoch': 1.7}\n",
            "{'loss': 0.3956, 'learning_rate': 2.1603733744957845e-05, 'epoch': 1.7}\n",
            "{'loss': 0.3986, 'learning_rate': 2.1482382179765355e-05, 'epoch': 1.71}\n",
            "{'loss': 0.3984, 'learning_rate': 2.136103061457287e-05, 'epoch': 1.72}\n",
            "{'loss': 0.3775, 'learning_rate': 2.123967904938038e-05, 'epoch': 1.73}\n",
            "{'loss': 0.3749, 'learning_rate': 2.111832748418789e-05, 'epoch': 1.73}\n",
            "{'loss': 0.4149, 'learning_rate': 2.0996975918995403e-05, 'epoch': 1.74}\n",
            "{'loss': 0.3603, 'learning_rate': 2.0875624353802917e-05, 'epoch': 1.75}\n",
            "{'loss': 0.374, 'learning_rate': 2.075427278861043e-05, 'epoch': 1.75}\n",
            "{'loss': 0.3764, 'learning_rate': 2.063292122341794e-05, 'epoch': 1.76}\n",
            "{'loss': 0.4116, 'learning_rate': 2.051156965822545e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3939, 'learning_rate': 2.0390218093032965e-05, 'epoch': 1.78}\n",
            "{'loss': 0.4017, 'learning_rate': 2.0268866527840475e-05, 'epoch': 1.78}\n",
            "{'loss': 0.3963, 'learning_rate': 2.014751496264799e-05, 'epoch': 1.79}\n",
            "{'loss': 0.3926, 'learning_rate': 2.0026163397455503e-05, 'epoch': 1.8}\n",
            "{'loss': 0.3712, 'learning_rate': 1.9904811832263013e-05, 'epoch': 1.81}\n",
            "{'loss': 0.3885, 'learning_rate': 1.9783460267070523e-05, 'epoch': 1.81}\n",
            "{'loss': 0.3952, 'learning_rate': 1.9662108701878037e-05, 'epoch': 1.82}\n",
            "{'loss': 0.3987, 'learning_rate': 1.954075713668555e-05, 'epoch': 1.83}\n",
            "{'loss': 0.3926, 'learning_rate': 1.941940557149306e-05, 'epoch': 1.83}\n",
            "{'loss': 0.3763, 'learning_rate': 1.9298054006300575e-05, 'epoch': 1.84}\n",
            "{'loss': 0.3971, 'learning_rate': 1.9176702441108085e-05, 'epoch': 1.85}\n",
            "{'loss': 0.3821, 'learning_rate': 1.90553508759156e-05, 'epoch': 1.86}\n",
            "{'loss': 0.3585, 'learning_rate': 1.893399931072311e-05, 'epoch': 1.86}\n",
            "{'loss': 0.4113, 'learning_rate': 1.8812647745530623e-05, 'epoch': 1.87}\n",
            "{'loss': 0.3823, 'learning_rate': 1.8691296180338137e-05, 'epoch': 1.88}\n",
            "{'loss': 0.3819, 'learning_rate': 1.8569944615145647e-05, 'epoch': 1.89}\n",
            "{'loss': 0.3761, 'learning_rate': 1.8448593049953157e-05, 'epoch': 1.89}\n",
            "{'loss': 0.3765, 'learning_rate': 1.832724148476067e-05, 'epoch': 1.9}\n",
            "{'loss': 0.3746, 'learning_rate': 1.8205889919568185e-05, 'epoch': 1.91}\n",
            "{'loss': 0.3849, 'learning_rate': 1.8084538354375695e-05, 'epoch': 1.91}\n",
            "{'loss': 0.3874, 'learning_rate': 1.796318678918321e-05, 'epoch': 1.92}\n",
            "{'loss': 0.3609, 'learning_rate': 1.784183522399072e-05, 'epoch': 1.93}\n",
            "{'loss': 0.372, 'learning_rate': 1.7720483658798233e-05, 'epoch': 1.94}\n",
            "{'loss': 0.402, 'learning_rate': 1.7599132093605743e-05, 'epoch': 1.94}\n",
            "{'loss': 0.3851, 'learning_rate': 1.7477780528413257e-05, 'epoch': 1.95}\n",
            "{'loss': 0.3863, 'learning_rate': 1.735642896322077e-05, 'epoch': 1.96}\n",
            "{'loss': 0.405, 'learning_rate': 1.723507739802828e-05, 'epoch': 1.97}\n",
            "{'loss': 0.3849, 'learning_rate': 1.711372583283579e-05, 'epoch': 1.97}\n",
            "{'loss': 0.3839, 'learning_rate': 1.6992374267643305e-05, 'epoch': 1.98}\n",
            "{'loss': 0.3665, 'learning_rate': 1.687102270245082e-05, 'epoch': 1.99}\n",
            "{'loss': 0.3814, 'learning_rate': 1.674967113725833e-05, 'epoch': 2.0}\n",
            "{'loss': 0.3649, 'learning_rate': 1.6628319572065842e-05, 'epoch': 2.0}\n",
            "{'loss': 0.344, 'learning_rate': 1.6506968006873353e-05, 'epoch': 2.01}\n",
            "{'loss': 0.3558, 'learning_rate': 1.6385616441680866e-05, 'epoch': 2.02}\n",
            "{'loss': 0.3355, 'learning_rate': 1.6264264876488377e-05, 'epoch': 2.02}\n",
            "{'loss': 0.3357, 'learning_rate': 1.614291331129589e-05, 'epoch': 2.03}\n",
            "{'loss': 0.3473, 'learning_rate': 1.6021561746103404e-05, 'epoch': 2.04}\n",
            "{'loss': 0.355, 'learning_rate': 1.5900210180910914e-05, 'epoch': 2.05}\n",
            "{'loss': 0.3628, 'learning_rate': 1.5778858615718425e-05, 'epoch': 2.05}\n",
            "{'loss': 0.3745, 'learning_rate': 1.565750705052594e-05, 'epoch': 2.06}\n",
            "{'loss': 0.3663, 'learning_rate': 1.5536155485333452e-05, 'epoch': 2.07}\n",
            "{'loss': 0.3325, 'learning_rate': 1.5414803920140962e-05, 'epoch': 2.08}\n",
            "{'loss': 0.3625, 'learning_rate': 1.5293452354948476e-05, 'epoch': 2.08}\n",
            "{'loss': 0.3585, 'learning_rate': 1.5172100789755986e-05, 'epoch': 2.09}\n",
            "{'loss': 0.3258, 'learning_rate': 1.5050749224563498e-05, 'epoch': 2.1}\n",
            "{'loss': 0.3387, 'learning_rate': 1.492939765937101e-05, 'epoch': 2.1}\n",
            "{'loss': 0.3689, 'learning_rate': 1.4808046094178524e-05, 'epoch': 2.11}\n",
            "{'loss': 0.3581, 'learning_rate': 1.4686694528986036e-05, 'epoch': 2.12}\n",
            "{'loss': 0.3476, 'learning_rate': 1.456534296379355e-05, 'epoch': 2.13}\n",
            "{'loss': 0.3547, 'learning_rate': 1.4443991398601058e-05, 'epoch': 2.13}\n",
            "{'loss': 0.363, 'learning_rate': 1.4322639833408572e-05, 'epoch': 2.14}\n",
            "{'loss': 0.3736, 'learning_rate': 1.4201288268216084e-05, 'epoch': 2.15}\n",
            "{'loss': 0.3525, 'learning_rate': 1.4079936703023596e-05, 'epoch': 2.16}\n",
            "{'loss': 0.3469, 'learning_rate': 1.395858513783111e-05, 'epoch': 2.16}\n",
            "{'loss': 0.3471, 'learning_rate': 1.383723357263862e-05, 'epoch': 2.17}\n",
            "{'loss': 0.3607, 'learning_rate': 1.3715882007446132e-05, 'epoch': 2.18}\n",
            "{'loss': 0.3407, 'learning_rate': 1.3594530442253644e-05, 'epoch': 2.18}\n",
            "{'loss': 0.3514, 'learning_rate': 1.3473178877061158e-05, 'epoch': 2.19}\n",
            "{'loss': 0.362, 'learning_rate': 1.335182731186867e-05, 'epoch': 2.2}\n",
            "{'loss': 0.3606, 'learning_rate': 1.3230475746676182e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3343, 'learning_rate': 1.3109124181483692e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3532, 'learning_rate': 1.2987772616291204e-05, 'epoch': 2.22}\n",
            "{'loss': 0.3364, 'learning_rate': 1.2866421051098718e-05, 'epoch': 2.23}\n",
            "{'loss': 0.3421, 'learning_rate': 1.274506948590623e-05, 'epoch': 2.24}\n",
            "{'loss': 0.3681, 'learning_rate': 1.2623717920713744e-05, 'epoch': 2.24}\n",
            "{'loss': 0.3443, 'learning_rate': 1.2502366355521252e-05, 'epoch': 2.25}\n",
            "{'loss': 0.361, 'learning_rate': 1.2381014790328768e-05, 'epoch': 2.26}\n",
            "{'loss': 0.3496, 'learning_rate': 1.2259663225136278e-05, 'epoch': 2.26}\n",
            "{'loss': 0.3607, 'learning_rate': 1.213831165994379e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3571, 'learning_rate': 1.2016960094751304e-05, 'epoch': 2.28}\n",
            "{'loss': 0.3671, 'learning_rate': 1.1895608529558814e-05, 'epoch': 2.29}\n",
            "{'loss': 0.3694, 'learning_rate': 1.1774256964366328e-05, 'epoch': 2.29}\n",
            "{'loss': 0.3446, 'learning_rate': 1.1652905399173838e-05, 'epoch': 2.3}\n",
            "{'loss': 0.3393, 'learning_rate': 1.1531553833981352e-05, 'epoch': 2.31}\n",
            "{'loss': 0.3658, 'learning_rate': 1.1410202268788864e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3504, 'learning_rate': 1.1288850703596376e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3596, 'learning_rate': 1.1167499138403888e-05, 'epoch': 2.33}\n",
            "{'loss': 0.3518, 'learning_rate': 1.10461475732114e-05, 'epoch': 2.34}\n",
            "{'loss': 0.3522, 'learning_rate': 1.0924796008018912e-05, 'epoch': 2.34}\n",
            "{'loss': 0.3461, 'learning_rate': 1.0803444442826424e-05, 'epoch': 2.35}\n",
            "{'loss': 0.3327, 'learning_rate': 1.0682092877633937e-05, 'epoch': 2.36}\n",
            "{'loss': 0.3261, 'learning_rate': 1.0560741312441448e-05, 'epoch': 2.37}\n",
            "{'loss': 0.3542, 'learning_rate': 1.0439389747248961e-05, 'epoch': 2.37}\n",
            "{'loss': 0.3525, 'learning_rate': 1.0318038182056472e-05, 'epoch': 2.38}\n",
            "{'loss': 0.3642, 'learning_rate': 1.0196686616863985e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3427, 'learning_rate': 1.0075335051671497e-05, 'epoch': 2.4}\n",
            "{'loss': 0.3533, 'learning_rate': 9.95398348647901e-06, 'epoch': 2.4}\n",
            "{'loss': 0.3606, 'learning_rate': 9.832631921286521e-06, 'epoch': 2.41}\n",
            "{'loss': 0.3387, 'learning_rate': 9.711280356094033e-06, 'epoch': 2.42}\n",
            "{'loss': 0.3487, 'learning_rate': 9.589928790901545e-06, 'epoch': 2.42}\n",
            "{'loss': 0.3375, 'learning_rate': 9.468577225709057e-06, 'epoch': 2.43}\n",
            "{'loss': 0.3602, 'learning_rate': 9.347225660516571e-06, 'epoch': 2.44}\n",
            "{'loss': 0.3422, 'learning_rate': 9.225874095324081e-06, 'epoch': 2.45}\n",
            "{'loss': 0.3407, 'learning_rate': 9.104522530131595e-06, 'epoch': 2.45}\n",
            "{'loss': 0.3535, 'learning_rate': 8.983170964939107e-06, 'epoch': 2.46}\n",
            "{'loss': 0.3676, 'learning_rate': 8.861819399746617e-06, 'epoch': 2.47}\n",
            "{'loss': 0.353, 'learning_rate': 8.740467834554131e-06, 'epoch': 2.48}\n",
            "{'loss': 0.3494, 'learning_rate': 8.619116269361641e-06, 'epoch': 2.48}\n",
            "{'loss': 0.331, 'learning_rate': 8.497764704169155e-06, 'epoch': 2.49}\n",
            "{'loss': 0.3572, 'learning_rate': 8.376413138976667e-06, 'epoch': 2.5}\n",
            "{'loss': 0.3357, 'learning_rate': 8.255061573784179e-06, 'epoch': 2.5}\n",
            "{'loss': 0.3755, 'learning_rate': 8.133710008591691e-06, 'epoch': 2.51}\n",
            "{'loss': 0.3271, 'learning_rate': 8.012358443399203e-06, 'epoch': 2.52}\n",
            "{'loss': 0.3569, 'learning_rate': 7.891006878206715e-06, 'epoch': 2.53}\n",
            "{'loss': 0.3373, 'learning_rate': 7.769655313014227e-06, 'epoch': 2.53}\n",
            "{'loss': 0.342, 'learning_rate': 7.64830374782174e-06, 'epoch': 2.54}\n",
            "{'loss': 0.3497, 'learning_rate': 7.526952182629252e-06, 'epoch': 2.55}\n",
            "{'loss': 0.3394, 'learning_rate': 7.405600617436764e-06, 'epoch': 2.56}\n",
            "{'loss': 0.3194, 'learning_rate': 7.284249052244275e-06, 'epoch': 2.56}\n",
            "{'loss': 0.3568, 'learning_rate': 7.162897487051788e-06, 'epoch': 2.57}\n",
            "{'loss': 0.3413, 'learning_rate': 7.041545921859301e-06, 'epoch': 2.58}\n",
            "{'loss': 0.3634, 'learning_rate': 6.920194356666812e-06, 'epoch': 2.58}\n",
            "{'loss': 0.3263, 'learning_rate': 6.798842791474325e-06, 'epoch': 2.59}\n",
            "{'loss': 0.3384, 'learning_rate': 6.677491226281838e-06, 'epoch': 2.6}\n",
            "{'loss': 0.341, 'learning_rate': 6.556139661089349e-06, 'epoch': 2.61}\n",
            "{'loss': 0.332, 'learning_rate': 6.434788095896861e-06, 'epoch': 2.61}\n",
            "{'loss': 0.3452, 'learning_rate': 6.313436530704374e-06, 'epoch': 2.62}\n",
            "{'loss': 0.3377, 'learning_rate': 6.192084965511886e-06, 'epoch': 2.63}\n",
            "{'loss': 0.3229, 'learning_rate': 6.070733400319398e-06, 'epoch': 2.64}\n",
            "{'loss': 0.3468, 'learning_rate': 5.94938183512691e-06, 'epoch': 2.64}\n",
            "{'loss': 0.3329, 'learning_rate': 5.828030269934422e-06, 'epoch': 2.65}\n",
            "{'loss': 0.3708, 'learning_rate': 5.7066787047419345e-06, 'epoch': 2.66}\n",
            "{'loss': 0.3628, 'learning_rate': 5.5853271395494466e-06, 'epoch': 2.66}\n",
            "{'loss': 0.3399, 'learning_rate': 5.4639755743569586e-06, 'epoch': 2.67}\n",
            "{'loss': 0.3396, 'learning_rate': 5.34262400916447e-06, 'epoch': 2.68}\n",
            "{'loss': 0.3429, 'learning_rate': 5.2212724439719826e-06, 'epoch': 2.69}\n",
            "{'loss': 0.3301, 'learning_rate': 5.0999208787794946e-06, 'epoch': 2.69}\n",
            "{'loss': 0.3442, 'learning_rate': 4.9785693135870066e-06, 'epoch': 2.7}\n",
            "{'loss': 0.3288, 'learning_rate': 4.857217748394519e-06, 'epoch': 2.71}\n",
            "{'loss': 0.3651, 'learning_rate': 4.7358661832020314e-06, 'epoch': 2.72}\n",
            "{'loss': 0.3592, 'learning_rate': 4.6145146180095434e-06, 'epoch': 2.72}\n",
            "{'loss': 0.3425, 'learning_rate': 4.4931630528170554e-06, 'epoch': 2.73}\n",
            "{'loss': 0.3775, 'learning_rate': 4.3718114876245674e-06, 'epoch': 2.74}\n",
            "{'loss': 0.3603, 'learning_rate': 4.2504599224320794e-06, 'epoch': 2.74}\n",
            "{'loss': 0.3278, 'learning_rate': 4.1291083572395914e-06, 'epoch': 2.75}\n",
            "{'loss': 0.3489, 'learning_rate': 4.007756792047104e-06, 'epoch': 2.76}\n",
            "{'loss': 0.3389, 'learning_rate': 3.886405226854616e-06, 'epoch': 2.77}\n",
            "{'loss': 0.3637, 'learning_rate': 3.7650536616621283e-06, 'epoch': 2.77}\n",
            "{'loss': 0.3542, 'learning_rate': 3.6437020964696403e-06, 'epoch': 2.78}\n",
            "{'loss': 0.3479, 'learning_rate': 3.5223505312771527e-06, 'epoch': 2.79}\n",
            "{'loss': 0.3417, 'learning_rate': 3.4009989660846647e-06, 'epoch': 2.8}\n",
            "{'loss': 0.3362, 'learning_rate': 3.2796474008921767e-06, 'epoch': 2.8}\n",
            "{'loss': 0.3219, 'learning_rate': 3.158295835699689e-06, 'epoch': 2.81}\n",
            "{'loss': 0.3693, 'learning_rate': 3.036944270507201e-06, 'epoch': 2.82}\n",
            "{'loss': 0.3333, 'learning_rate': 2.915592705314713e-06, 'epoch': 2.83}\n",
            "{'loss': 0.3207, 'learning_rate': 2.7942411401222256e-06, 'epoch': 2.83}\n",
            "{'loss': 0.3441, 'learning_rate': 2.6728895749297376e-06, 'epoch': 2.84}\n",
            "{'loss': 0.3275, 'learning_rate': 2.5515380097372496e-06, 'epoch': 2.85}\n",
            "{'loss': 0.3547, 'learning_rate': 2.4301864445447616e-06, 'epoch': 2.85}\n",
            "{'loss': 0.3365, 'learning_rate': 2.308834879352274e-06, 'epoch': 2.86}\n",
            "{'loss': 0.3455, 'learning_rate': 2.1874833141597865e-06, 'epoch': 2.87}\n",
            "{'loss': 0.324, 'learning_rate': 2.066131748967298e-06, 'epoch': 2.88}\n",
            "{'loss': 0.3493, 'learning_rate': 1.9447801837748105e-06, 'epoch': 2.88}\n",
            "{'loss': 0.335, 'learning_rate': 1.8234286185823225e-06, 'epoch': 2.89}\n",
            "{'loss': 0.3463, 'learning_rate': 1.7020770533898347e-06, 'epoch': 2.9}\n",
            "{'loss': 0.3129, 'learning_rate': 1.5807254881973467e-06, 'epoch': 2.91}\n",
            "{'loss': 0.3724, 'learning_rate': 1.459373923004859e-06, 'epoch': 2.91}\n",
            "{'loss': 0.361, 'learning_rate': 1.3380223578123711e-06, 'epoch': 2.92}\n",
            "{'loss': 0.3498, 'learning_rate': 1.2166707926198831e-06, 'epoch': 2.93}\n",
            "{'loss': 0.3257, 'learning_rate': 1.0953192274273953e-06, 'epoch': 2.93}\n",
            "{'loss': 0.3464, 'learning_rate': 9.739676622349076e-07, 'epoch': 2.94}\n",
            " 98% 202165/206013 [3:14:37<03:05, 20.72it/s]"
          ]
        }
      ]
    }
  ]
}